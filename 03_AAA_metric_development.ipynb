{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4567380",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"C:/Users/russe/OneDrive/Desktop/Portfolio/Next AAA Title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings_df = pd.read_csv(\n",
    "        f'{data_path}/Processed/movies_ratings.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "movies_df = pd.read_csv(\n",
    "        f'{data_path}/Raw/movies.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "ratings_df = pd.read_csv(\n",
    "        f'{data_path}/Raw/ratings.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "actors_df = pd.read_csv(\n",
    "        f'{data_path}/Raw/actors.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "principals_df = pd.read_csv(\n",
    "        f'{data_path}/Raw/principals.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "movies_metrics_df = pd.read_csv(\n",
    "        f'{data_path}/Processed/movies_metrics.csv',\n",
    "        sep=','\n",
    "    )\n",
    "\n",
    "actors_metrics_df = pd.read_csv(\n",
    "        f'{data_path}/Processed/actors_metrics.csv',\n",
    "        sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2199b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "SCORING_METHOD = 'percentile'  # Options: 'percentile', 'robust', 'zscore'\n",
    "\n",
    "COMPONENT_WEIGHTS = {\n",
    "    'critical_reception': 0.30,\n",
    "    'commercial_proxy': 0.25,\n",
    "    'audience_engagement': 0.25,\n",
    "    'actor_popularity': 0.20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(series, method='percentile'):\n",
    "\n",
    "    # Remove NaN values for calculation\n",
    "    valid_data = series.dropna()\n",
    "    \n",
    "    if len(valid_data) == 0:\n",
    "        return pd.Series(50, index=series.index)  # Default to middle score\n",
    "    \n",
    "    if method == 'percentile':\n",
    "        # Percentile ranking (most stable distribution)\n",
    "        normalized = series.rank(pct=True, method='average') * 100\n",
    "        \n",
    "    elif method == 'robust':\n",
    "        # RobustScaler: handles outliers better than MinMaxScaler\n",
    "        scaler = RobustScaler()\n",
    "        scaled = scaler.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "        # Convert to 0-100 range (using 5th and 95th percentiles as bounds)\n",
    "        p5, p95 = np.percentile(scaled, [5, 95])\n",
    "        normalized = pd.Series(\n",
    "            np.clip((scaled - p5) / (p95 - p5) * 100, 0, 100),\n",
    "            index=series.index\n",
    "        )\n",
    "        \n",
    "    elif method == 'zscore':\n",
    "        # Z-score with sigmoid transformation\n",
    "        z_scores = stats.zscore(valid_data)\n",
    "        # Sigmoid transformation to 0-100\n",
    "        sigmoid = 1 / (1 + np.exp(-z_scores/2))\n",
    "        normalized = pd.Series(sigmoid * 100, index=valid_data.index)\n",
    "        normalized = normalized.reindex(series.index, fill_value=50)\n",
    "        \n",
    "    else:\n",
    "        # Fallback to percentile\n",
    "        normalized = series.rank(pct=True, method='average') * 100\n",
    "        \n",
    "    return normalized\n",
    "\n",
    "\n",
    "def print_score_statistics(df, score_column, component_name):\n",
    "    \"\"\"\n",
    "    Print statistics for a score component.\n",
    "    \"\"\"\n",
    "    print(f\"\\n✅ {component_name} Statistics:\")\n",
    "    print(f\"   Mean: {df[score_column].mean():.1f}\")\n",
    "    print(f\"   Median: {df[score_column].median():.1f}\")\n",
    "    print(f\"   Std Dev: {df[score_column].std():.1f}\")\n",
    "    print(f\"   Min: {df[score_column].min():.1f}\")\n",
    "    print(f\"   Max: {df[score_column].max():.1f}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Critical Reception Score Function\n",
    "# ============================================\n",
    "\n",
    "def calculate_critical_reception_score(df, method='percentile'):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 CALCULATING CRITICAL RECEPTION SCORE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Weighted rating (Bayesian average for credibility)\n",
    "    m = df['numVotes'].quantile(0.25)  # Use 25th percentile as minimum threshold\n",
    "    C = df['averageRating'].median()    # Use median for robustness\n",
    "    \n",
    "    df['weighted_rating'] = (\n",
    "        (df['numVotes'] / (df['numVotes'] + m)) * df['averageRating'] +\n",
    "        (m / (df['numVotes'] + m)) * C\n",
    "    )\n",
    "    \n",
    "    # 2. Rating variance (lower variance = consistent appeal)\n",
    "    median_rating = df['averageRating'].median()\n",
    "    df['rating_consistency'] = np.exp(-abs(df['averageRating'] - median_rating) / 2)\n",
    "    \n",
    "    # 3. Vote credibility factor\n",
    "    df['vote_credibility'] = np.log10(df['numVotes'] + 10) / np.log10(df['numVotes'].max() + 10)\n",
    "    \n",
    "    # Normalize components\n",
    "    df['weighted_rating_norm'] = normalize_score(df['weighted_rating'], method)\n",
    "    df['rating_consistency_norm'] = normalize_score(df['rating_consistency'], method)\n",
    "    df['vote_credibility_norm'] = normalize_score(df['vote_credibility'], method)\n",
    "    \n",
    "    # Combined score with weights\n",
    "    df['critical_reception_score'] = (\n",
    "        0.60 * df['weighted_rating_norm'] +\n",
    "        0.25 * df['rating_consistency_norm'] +\n",
    "        0.15 * df['vote_credibility_norm']\n",
    "    )\n",
    "    \n",
    "    print_score_statistics(df, 'critical_reception_score', 'Critical Reception Score')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Commercial Proxy Score Function\n",
    "# ============================================\n",
    "\n",
    "def calculate_commercial_proxy_score(df, method='percentile'):\n",
    " \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"💰 CALCULATING COMMERCIAL PROXY SCORE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Audience reach (logarithmic scale)\n",
    "    df['audience_reach'] = np.log10(df['numVotes'] + 1)\n",
    "    \n",
    "    # 2. Genre-relative performance (vectorized)\n",
    "    # Pre-calculate genre medians once\n",
    "    genre_stats = {}\n",
    "    if 'genres' in df.columns:\n",
    "        all_genres = set()\n",
    "        for genres in df['genres'].dropna():\n",
    "            all_genres.update([g.strip() for g in genres.split(',')])\n",
    "        \n",
    "        for genre in all_genres:\n",
    "            genre_movies = df[df['genres'].str.contains(genre, na=False)]\n",
    "            if len(genre_movies) > 0:\n",
    "                genre_stats[genre] = {\n",
    "                    'median_votes': genre_movies['numVotes'].median(),\n",
    "                    'median_rating': genre_movies['averageRating'].median()\n",
    "                }\n",
    "    \n",
    "    # Calculate genre performance efficiently\n",
    "    def get_genre_performance(row):\n",
    "        if pd.isna(row['genres']) or not genre_stats:\n",
    "            return 1.0\n",
    "        \n",
    "        genres = [g.strip() for g in row['genres'].split(',')]\n",
    "        median_votes = [genre_stats.get(g, {}).get('median_votes', row['numVotes']) \n",
    "                      for g in genres]\n",
    "        \n",
    "        if median_votes:\n",
    "            return row['numVotes'] / max(median_votes)\n",
    "        return 1.0\n",
    "    \n",
    "    df['genre_relative_performance'] = df.apply(get_genre_performance, axis=1)\n",
    "    \n",
    "    # 3. Market penetration (percentile within release year)\n",
    "    if 'startYear' in df.columns:\n",
    "        df['year_percentile'] = df.groupby('startYear')['numVotes'].rank(pct=True) * 100\n",
    "    else:\n",
    "        df['year_percentile'] = 50  # Default if no year data\n",
    "    \n",
    "    # Normalize components\n",
    "    df['audience_reach_norm'] = normalize_score(df['audience_reach'], method)\n",
    "    df['genre_relative_norm'] = normalize_score(df['genre_relative_performance'], method)\n",
    "    df['year_percentile_norm'] = df['year_percentile']  # Already in percentile\n",
    "    \n",
    "    # Combined score\n",
    "    df['commercial_proxy_score'] = (\n",
    "        0.50 * df['audience_reach_norm'] +\n",
    "        0.30 * df['genre_relative_norm'] +\n",
    "        0.20 * df['year_percentile_norm']\n",
    "    )\n",
    "    \n",
    "    print_score_statistics(df, 'commercial_proxy_score', 'Commercial Proxy Score')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Audience Engagement Score Function\n",
    "# ============================================\n",
    "\n",
    "def calculate_audience_engagement_score(df, method='percentile'):\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"👥 CALCULATING AUDIENCE ENGAGEMENT SCORE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Rating achievement (continuous, not binary)\n",
    "    # Sigmoid function for smooth transition around 7.0 threshold\n",
    "    df['rating_achievement'] = 100 / (1 + np.exp(-2 * (df['averageRating'] - 7.0)))\n",
    "    \n",
    "    # 2. Engagement velocity (rating * log(votes))\n",
    "    df['engagement_velocity'] = df['averageRating'] * np.log10(df['numVotes'] + 1)\n",
    "    \n",
    "    # 3. Entertainment efficiency (quality per hour)\n",
    "    # Handle missing runtime with median\n",
    "    median_runtime = df['runtimeMinutes'].median() if 'runtimeMinutes' in df.columns else 120\n",
    "    if 'runtimeMinutes' in df.columns:\n",
    "        df['runtime_clean'] = df['runtimeMinutes'].fillna(median_runtime)\n",
    "    else:\n",
    "        df['runtime_clean'] = median_runtime\n",
    "    \n",
    "    df['entertainment_efficiency'] = (df['averageRating'] * 60) / df['runtime_clean'].clip(lower=30)\n",
    "    \n",
    "    # 4. Audience consensus (inverse of rating variance, simulated)\n",
    "    df['audience_consensus'] = (df['averageRating'] / 10) * np.log10(df['numVotes'] + 1)\n",
    "    \n",
    "    # Normalize components\n",
    "    df['rating_achievement_norm'] = normalize_score(df['rating_achievement'], method)\n",
    "    df['engagement_velocity_norm'] = normalize_score(df['engagement_velocity'], method)\n",
    "    df['entertainment_efficiency_norm'] = normalize_score(df['entertainment_efficiency'], method)\n",
    "    df['audience_consensus_norm'] = normalize_score(df['audience_consensus'], method)\n",
    "    \n",
    "    # Combined score\n",
    "    df['audience_engagement_score'] = (\n",
    "        0.35 * df['rating_achievement_norm'] +\n",
    "        0.30 * df['engagement_velocity_norm'] +\n",
    "        0.20 * df['entertainment_efficiency_norm'] +\n",
    "        0.15 * df['audience_consensus_norm']\n",
    "    )\n",
    "    \n",
    "    print_score_statistics(df, 'audience_engagement_score', 'Audience Engagement Score')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_actor_popularity_score(\n",
    "    movies_df, \n",
    "    actor_metrics_df, \n",
    "    principals_df,\n",
    "    min_actors: int = 1,\n",
    "    verbose: bool = True\n",
    ") :\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validate input DataFrames\n",
    "    try:\n",
    "        # Check required columns\n",
    "        if 'tconst' not in movies_df.columns:\n",
    "            raise ValueError(\"movies_df must contain 'tconst' column\")\n",
    "        \n",
    "        required_actor_cols = ['nconst', 'popularity_score']\n",
    "        missing_cols = [col for col in required_actor_cols if col not in actor_metrics_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"actor_metrics_df missing columns: {missing_cols}\")\n",
    "        \n",
    "        required_principals_cols = ['tconst', 'nconst', 'category']\n",
    "        missing_cols = [col for col in required_principals_cols if col not in principals_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"principals_df missing columns: {missing_cols}\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Validation Error: {e}\")\n",
    "        return movies_df\n",
    "    \n",
    "    # Start processing\n",
    "    start_time = pd.Timestamp.now()\n",
    "    \n",
    "    # Step 1: Filter principals to only actors/actresses\n",
    "    actor_principals = principals_df[\n",
    "        principals_df['category'].isin(['actor', 'actress'])\n",
    "    ].copy()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"✅ Filtered to {len(actor_principals):,} actor/actress records\")\n",
    "    \n",
    "    # Step 2: Merge with actor popularity scores (vectorized operation)\n",
    "    actor_principals_with_scores = actor_principals.merge(\n",
    "        actor_metrics_df[['nconst', 'popularity_score']],\n",
    "        on='nconst',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Filter out actors without popularity scores\n",
    "    actor_principals_with_scores = actor_principals_with_scores[\n",
    "        actor_principals_with_scores['popularity_score'].notna() & \n",
    "        (actor_principals_with_scores['popularity_score'] > 0)\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"✅ Found popularity scores for {len(actor_principals_with_scores):,} cast records\")\n",
    "    \n",
    "    # Step 3: Calculate aggregated metrics per movie (vectorized groupby)\n",
    "    movie_actor_metrics = actor_principals_with_scores.groupby('tconst').agg({\n",
    "        'popularity_score': ['mean', 'sum', 'max', 'std', 'count']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    movie_actor_metrics.columns = [\n",
    "        'actor_popularity_score',  # average\n",
    "        'total_cast_popularity',   # sum\n",
    "        'max_actor_popularity',    # max\n",
    "        'actor_popularity_std',    # standard deviation\n",
    "        'cast_actor_count'        # count\n",
    "    ]\n",
    "    movie_actor_metrics.reset_index(inplace=True)\n",
    "    \n",
    "    # Step 4: Merge back with movies_df (vectorized merge)\n",
    "    result_df = movies_df.merge(\n",
    "        movie_actor_metrics,\n",
    "        on='tconst',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Step 5: Handle missing values\n",
    "    result_df['actor_popularity_score'] = result_df['actor_popularity_score'].fillna(0)\n",
    "    result_df['total_cast_popularity'] = result_df['total_cast_popularity'].fillna(0)\n",
    "    result_df['max_actor_popularity'] = result_df['max_actor_popularity'].fillna(0)\n",
    "    result_df['actor_popularity_std'] = result_df['actor_popularity_std'].fillna(0)\n",
    "    result_df['cast_actor_count'] = result_df['cast_actor_count'].fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    result_df['cast_diversity_score'] = np.where(\n",
    "        result_df['actor_popularity_score'] > 0,\n",
    "        result_df['actor_popularity_std'] / result_df['actor_popularity_score'],\n",
    "        0\n",
    "    ).round(3)\n",
    "    \n",
    "    # Processing time\n",
    "    processing_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "    \n",
    "    if verbose:\n",
    "        # Summary statistics\n",
    "        movies_with_cast = result_df[result_df['cast_actor_count'] >= min_actors]\n",
    "        \n",
    "        print(f\"\\n📊 PROCESSING SUMMARY:\")\n",
    "        print(f\"   Processing time: {processing_time:.2f} seconds\")\n",
    "        print(f\"   Total movies processed: {len(result_df):,}\")\n",
    "        print(f\"   Movies with cast data: {len(movies_with_cast):,}\")\n",
    "        print(f\"   Average Actor Score: {movies_with_cast['actor_popularity_score'].mean():.2f}\")\n",
    "        print(f\"   Median Actor Score: {movies_with_cast['actor_popularity_score'].median():.2f}\")\n",
    "        print(f\"   Max Actor Score: {movies_with_cast['actor_popularity_score'].max():.2f}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "#  Actor Popularity Normalization Function\n",
    "# ============================================\n",
    "\n",
    "def normalize_actor_popularity_score(df, method='percentile'):\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🌟 NORMALIZING ACTOR POPULARITY SCORE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if 'actor_popularity_score' not in df.columns:\n",
    "        print(\"⚠️ Warning: actor_popularity_score column not found\")\n",
    "        print(\"   Creating default score of 50\")\n",
    "        df['actor_popularity_score'] = 50\n",
    "        df['actor_popularity_score_norm'] = 50\n",
    "        return df\n",
    "    \n",
    "    # Apply normalization\n",
    "    df['actor_popularity_score_norm'] = normalize_score(df['actor_popularity_score'], method)\n",
    "    \n",
    "    print_score_statistics(df, 'actor_popularity_score_norm', 'Actor Popularity Score (Normalized)')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23953dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aaa_score(df, weights=None):\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🏆 CALCULATING FINAL AAA SCORE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = COMPONENT_WEIGHTS\n",
    "    \n",
    "    # Map component names to column names\n",
    "    score_columns = {\n",
    "        'critical_reception': 'critical_reception_score',\n",
    "        'commercial_proxy': 'commercial_proxy_score',\n",
    "        'audience_engagement': 'audience_engagement_score',\n",
    "        'actor_popularity': 'actor_popularity_score_norm'\n",
    "    }\n",
    "    \n",
    "    # Ensure all component scores exist\n",
    "    for component, column in score_columns.items():\n",
    "        if column not in df.columns:\n",
    "            print(f\"⚠️ Warning: {column} not found, using default value 50\")\n",
    "            df[column] = 50\n",
    "    \n",
    "    # Calculate weighted AAA score\n",
    "    df['aaa_score'] = sum(\n",
    "        weights[component] * df[column]\n",
    "        for component, column in score_columns.items()\n",
    "    )\n",
    "    \n",
    "    # Add score tier classification\n",
    "    df['score_tier'] = pd.cut(\n",
    "        df['aaa_score'],\n",
    "        bins=[0, 20, 40, 60, 80, 100],\n",
    "        labels=['F', 'D', 'C', 'B', 'A']\n",
    "    )\n",
    "    \n",
    "    # Print comprehensive statistics\n",
    "    print(f\"\\n📊 FINAL AAA SCORE DISTRIBUTION:\")\n",
    "    print(f\"   Mean: {df['aaa_score'].mean():.1f}\")\n",
    "    print(f\"   Median: {df['aaa_score'].median():.1f}\")\n",
    "    print(f\"   Std Dev: {df['aaa_score'].std():.1f}\")\n",
    "    print(f\"   Min: {df['aaa_score'].min():.1f}\")\n",
    "    print(f\"   Max: {df['aaa_score'].max():.1f}\")\n",
    "    \n",
    "    print(f\"\\n📈 SCORE PERCENTILES:\")\n",
    "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "    for p in percentiles:\n",
    "        value = np.percentile(df['aaa_score'].dropna(), p)\n",
    "        print(f\"   {p}th percentile: {value:.1f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 TIER DISTRIBUTION:\")\n",
    "    tier_dist = df['score_tier'].value_counts().sort_index()\n",
    "    for tier, count in tier_dist.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"   {tier}: {count:,} movies ({pct:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae7c3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_score_distribution(df, score_column):\n",
    "    \n",
    "    print(f\"\\n🔍 Validating {score_column} distribution...\")\n",
    "    \n",
    "    mean = df[score_column].mean()\n",
    "    median = df[score_column].median()\n",
    "    std = df[score_column].std()\n",
    "    min_val = df[score_column].min()\n",
    "    max_val = df[score_column].max()\n",
    "    \n",
    "    health_checks = {\n",
    "        'mean_near_50': 40 <= mean <= 60,\n",
    "        'median_near_50': 40 <= median <= 60,\n",
    "        'good_spread': 20 <= std <= 35,\n",
    "        'full_range': max_val - min_val > 70,\n",
    "        'min_reasonable': min_val < 20,\n",
    "        'max_reasonable': max_val > 80\n",
    "    }\n",
    "    \n",
    "    print(\"Distribution Health Check:\")\n",
    "    for check, passed in health_checks.items():\n",
    "        status = \"✅\" if passed else \"❌\"\n",
    "        print(f\"  {status} {check}\")\n",
    "    \n",
    "    all_passed = all(health_checks.values())\n",
    "    if all_passed:\n",
    "        print(f\"✅ {score_column} distribution is healthy!\")\n",
    "    else:\n",
    "        print(f\"⚠️ {score_column} distribution needs adjustment\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "\n",
    "def get_top_movies(df, n=10, score_column='aaa_score'):\n",
    "    \n",
    "    print(f\"\\n🏆 TOP {n} MOVIES BY {score_column.upper()}:\")\n",
    "    \n",
    "    # Select relevant columns for display\n",
    "    display_columns = ['primaryTitle', 'startYear', score_column]\n",
    "    if 'score_tier' in df.columns:\n",
    "        display_columns.append('score_tier')\n",
    "    \n",
    "    # Add other score components if they exist\n",
    "    optional_columns = ['averageRating', 'numVotes', 'genres']\n",
    "    for col in optional_columns:\n",
    "        if col in df.columns:\n",
    "            display_columns.append(col)\n",
    "    \n",
    "    top_movies = df.nlargest(n, score_column)[display_columns]\n",
    "    \n",
    "    for i, (idx, movie) in enumerate(top_movies.iterrows(), 1):\n",
    "        title = movie.get('primaryTitle', 'Unknown')\n",
    "        year = movie.get('startYear', 'N/A')\n",
    "        score = movie[score_column]\n",
    "        tier = movie.get('score_tier', 'N/A')\n",
    "        \n",
    "        print(f\"\\n{i:2d}. {title} ({year})\")\n",
    "        print(f\"    Score: {score:.1f} | Tier: {tier}\")\n",
    "        \n",
    "        if 'averageRating' in movie:\n",
    "            print(f\"    Rating: {movie['averageRating']:.1f} | Votes: {movie['numVotes']:,}\")\n",
    "    \n",
    "    return top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63b12ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_scoring_pipeline(movies_df, actor_metrics_df=None, principals_df=None, \n",
    "                                 scoring_method='percentile', validate=True):\n",
    "   \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🎬 STARTING MOVIE AAA SCORING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"📊 Processing {len(movies_df):,} movies\")\n",
    "    print(f\"📈 Using {scoring_method} normalization method\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df = movies_df.copy()\n",
    "    \n",
    "    # Step 1: Calculate Critical Reception Score\n",
    "    df = calculate_critical_reception_score(df, method=scoring_method)\n",
    "    if validate:\n",
    "        validate_score_distribution(df, 'critical_reception_score')\n",
    "    \n",
    "    # Step 2: Calculate Commercial Proxy Score\n",
    "    df = calculate_commercial_proxy_score(df, method=scoring_method)\n",
    "    if validate:\n",
    "        validate_score_distribution(df, 'commercial_proxy_score')\n",
    "    \n",
    "    # Step 3: Calculate Audience Engagement Score\n",
    "    df = calculate_audience_engagement_score(df, method=scoring_method)\n",
    "    if validate:\n",
    "        validate_score_distribution(df, 'audience_engagement_score')\n",
    "    \n",
    "    # Step 4: Calculate Actor Popularity Score (if data provided)\n",
    "    if actor_metrics_df is not None and principals_df is not None:\n",
    "        df = calculate_actor_popularity_score(\n",
    "            df, \n",
    "            actor_metrics_df, \n",
    "            principals_df,\n",
    "            verbose=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n⚠️ Actor metrics or principals data not provided\")\n",
    "        print(\"   Using default actor popularity score of 0\")\n",
    "        df['actor_popularity_score'] = 0\n",
    "    \n",
    "    # Step 5: Normalize Actor Popularity Score\n",
    "    df = normalize_actor_popularity_score(df, method=scoring_method)\n",
    "    if validate:\n",
    "        validate_score_distribution(df, 'actor_popularity_score_norm')\n",
    "    \n",
    "    # Step 6: Calculate Final AAA Score\n",
    "    df = calculate_aaa_score(df)\n",
    "    if validate:\n",
    "        validate_score_distribution(df, 'aaa_score')\n",
    "    \n",
    "    # Step 7: Show top movies\n",
    "    get_top_movies(df, n=10, score_column='aaa_score')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ SCORING PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a23c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🎬 STARTING MOVIE AAA SCORING PIPELINE\n",
      "======================================================================\n",
      "📊 Processing 152,447 movies\n",
      "📈 Using percentile normalization method\n",
      "\n",
      "============================================================\n",
      "📊 CALCULATING CRITICAL RECEPTION SCORE\n",
      "============================================================\n",
      "\n",
      "✅ Critical Reception Score Statistics:\n",
      "   Mean: 50.0\n",
      "   Median: 54.8\n",
      "   Std Dev: 19.4\n",
      "   Min: 5.8\n",
      "   Max: 81.8\n",
      "\n",
      "🔍 Validating critical_reception_score distribution...\n",
      "Distribution Health Check:\n",
      "  ✅ mean_near_50\n",
      "  ✅ median_near_50\n",
      "  ❌ good_spread\n",
      "  ✅ full_range\n",
      "  ✅ min_reasonable\n",
      "  ✅ max_reasonable\n",
      "⚠️ critical_reception_score distribution needs adjustment\n",
      "\n",
      "============================================================\n",
      "💰 CALCULATING COMMERCIAL PROXY SCORE\n",
      "============================================================\n",
      "\n",
      "✅ Commercial Proxy Score Statistics:\n",
      "   Mean: 50.0\n",
      "   Median: 49.1\n",
      "   Std Dev: 28.2\n",
      "   Min: 0.2\n",
      "   Max: 100.0\n",
      "\n",
      "🔍 Validating commercial_proxy_score distribution...\n",
      "Distribution Health Check:\n",
      "  ✅ mean_near_50\n",
      "  ✅ median_near_50\n",
      "  ✅ good_spread\n",
      "  ✅ full_range\n",
      "  ✅ min_reasonable\n",
      "  ✅ max_reasonable\n",
      "✅ commercial_proxy_score distribution is healthy!\n",
      "\n",
      "============================================================\n",
      "👥 CALCULATING AUDIENCE ENGAGEMENT SCORE\n",
      "============================================================\n",
      "\n",
      "✅ Audience Engagement Score Statistics:\n",
      "   Mean: 50.0\n",
      "   Median: 53.0\n",
      "   Std Dev: 21.6\n",
      "   Min: 0.0\n",
      "   Max: 99.1\n",
      "\n",
      "🔍 Validating audience_engagement_score distribution...\n",
      "Distribution Health Check:\n",
      "  ✅ mean_near_50\n",
      "  ✅ median_near_50\n",
      "  ✅ good_spread\n",
      "  ✅ full_range\n",
      "  ✅ min_reasonable\n",
      "  ✅ max_reasonable\n",
      "✅ audience_engagement_score distribution is healthy!\n",
      "\n",
      "============================================================\n",
      "🌟 CALCULATING ACTOR POPULARITY SCORE COMPONENT\n",
      "============================================================\n",
      "\n",
      "💡 WHAT IT MEASURES:\n",
      "Average popularity score of all actors in each movie\n",
      "\n",
      "🎯 BUSINESS LOGIC:\n",
      "• Simple average of all cast member popularity scores\n",
      "• Higher average = stronger overall cast\n",
      "• Reflects total star power of the movie\n",
      "        \n",
      "✅ Filtered to 1,516,184 actor/actress records\n",
      "✅ Found popularity scores for 1,219,967 cast records\n",
      "\n",
      "📊 PROCESSING SUMMARY:\n",
      "   Processing time: 1.69 seconds\n",
      "   Total movies processed: 152,447\n",
      "   Movies with cast data: 124,093\n",
      "   Average Actor Score: 10.60\n",
      "   Median Actor Score: 10.06\n",
      "   Max Actor Score: 42.40\n",
      "\n",
      "============================================================\n",
      "🌟 NORMALIZING ACTOR POPULARITY SCORE\n",
      "============================================================\n",
      "\n",
      "✅ Actor Popularity Score (Normalized) Statistics:\n",
      "   Mean: 50.0\n",
      "   Median: 49.9\n",
      "   Std Dev: 28.8\n",
      "   Min: 9.3\n",
      "   Max: 100.0\n",
      "\n",
      "🔍 Validating actor_popularity_score_norm distribution...\n",
      "Distribution Health Check:\n",
      "  ✅ mean_near_50\n",
      "  ✅ median_near_50\n",
      "  ✅ good_spread\n",
      "  ✅ full_range\n",
      "  ✅ min_reasonable\n",
      "  ✅ max_reasonable\n",
      "✅ actor_popularity_score_norm distribution is healthy!\n",
      "\n",
      "============================================================\n",
      "🏆 CALCULATING FINAL AAA SCORE\n",
      "============================================================\n",
      "\n",
      "📊 FINAL AAA SCORE DISTRIBUTION:\n",
      "   Mean: 50.0\n",
      "   Median: 48.8\n",
      "   Std Dev: 16.2\n",
      "   Min: 6.1\n",
      "   Max: 92.6\n",
      "\n",
      "📈 SCORE PERCENTILES:\n",
      "   10th percentile: 29.8\n",
      "   25th percentile: 38.1\n",
      "   50th percentile: 48.8\n",
      "   75th percentile: 61.1\n",
      "   90th percentile: 72.8\n",
      "   95th percentile: 79.4\n",
      "   99th percentile: 86.5\n",
      "\n",
      "🎯 TIER DISTRIBUTION:\n",
      "   F: 3,119 movies (2.0%)\n",
      "   D: 41,525 movies (27.2%)\n",
      "   C: 66,867 movies (43.9%)\n",
      "   B: 33,900 movies (22.2%)\n",
      "   A: 7,036 movies (4.6%)\n",
      "\n",
      "🔍 Validating aaa_score distribution...\n",
      "Distribution Health Check:\n",
      "  ✅ mean_near_50\n",
      "  ✅ median_near_50\n",
      "  ❌ good_spread\n",
      "  ✅ full_range\n",
      "  ✅ min_reasonable\n",
      "  ✅ max_reasonable\n",
      "⚠️ aaa_score distribution needs adjustment\n",
      "\n",
      "🏆 TOP 10 MOVIES BY AAA_SCORE:\n",
      "\n",
      " 1. Endless Corridor (2014.0)\n",
      "    Score: 92.6 | Tier: A\n",
      "    Rating: 8.1 | Votes: 42,258\n",
      "\n",
      " 2. The Grand Budapest Hotel (2014.0)\n",
      "    Score: 91.8 | Tier: A\n",
      "    Rating: 8.1 | Votes: 940,703\n",
      "\n",
      " 3. How to Train Your Dragon (2010.0)\n",
      "    Score: 91.8 | Tier: A\n",
      "    Rating: 8.1 | Votes: 866,208\n",
      "\n",
      " 4. Moonrise Kingdom (2012.0)\n",
      "    Score: 91.4 | Tier: A\n",
      "    Rating: 7.8 | Votes: 377,827\n",
      "\n",
      " 5. The Wild Robot (2024.0)\n",
      "    Score: 91.4 | Tier: A\n",
      "    Rating: 8.2 | Votes: 196,407\n",
      "\n",
      " 6. Drive (2011.0)\n",
      "    Score: 91.4 | Tier: A\n",
      "    Rating: 7.8 | Votes: 745,513\n",
      "\n",
      " 7. Whiplash (2014.0)\n",
      "    Score: 91.4 | Tier: A\n",
      "    Rating: 8.5 | Votes: 1,099,252\n",
      "\n",
      " 8. Inside Out (2015.0)\n",
      "    Score: 91.3 | Tier: A\n",
      "    Rating: 8.1 | Votes: 884,114\n",
      "\n",
      " 9. Toy Story 3 (2010.0)\n",
      "    Score: 91.3 | Tier: A\n",
      "    Rating: 8.3 | Votes: 944,816\n",
      "\n",
      "10. Klaus (2019.0)\n",
      "    Score: 91.3 | Tier: A\n",
      "    Rating: 8.2 | Votes: 219,624\n",
      "\n",
      "======================================================================\n",
      "✅ SCORING PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "scored_movies = run_complete_scoring_pipeline(\n",
    "    movies_metrics_df,\n",
    "    actor_metrics_df= actors_metrics_df,  # Optional\n",
    "    principals_df=principals_df,  # Optional\n",
    "    scoring_method='percentile',  # Options: 'percentile', 'robust', 'zscore'\n",
    "    validate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8de8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_movies.to_csv(f'{data_path}/Processed/movie_metrics_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54bb24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
